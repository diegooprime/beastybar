# configs/alphazero_v2_10sim.yaml
# AlphaZero V2 - FAST (10 MCTS simulations)
# Quick exploration run to validate training pipeline
# Est. training time: ~1-2 days on H100

network_config:
  hidden_dim: 256
  num_heads: 8
  queue_layers: 6
  bar_layers: 2
  hand_layers: 2
  fusion_layers: 4
  dropout: 0.1
  species_embedding_dim: 64
  use_dueling: true
  use_auxiliary_heads: true
  auxiliary_weight: 0.1

network_version: "v2"

# MCTS configuration (minimal search)
num_simulations: 10          # Fast - relies more on network prior
c_puct: 1.5
dirichlet_alpha: 0.3
dirichlet_epsilon: 0.25
temperature: 1.0
temperature_drop_move: 12
final_temperature: 0.1

# Parallel self-play
games_per_iteration: 512
parallel_games: 128

# Training schedule
total_iterations: 3000
batch_size: 4096
epochs_per_iteration: 4

# Optimization
learning_rate: 0.0001
weight_decay: 0.0001
max_grad_norm: 0.5
value_loss_weight: 1.0
auxiliary_loss_weight: 0.1

# Checkpointing and evaluation
checkpoint_frequency: 100
eval_frequency: 50
eval_games_per_opponent: 200

# Learning rate schedule
lr_warmup_iterations: 30
lr_decay: "cosine"

# Replay buffer
buffer_size: 1500000
min_buffer_size: 15000

# Performance
torch_compile: true
torch_compile_mode: "reduce-overhead"

# Tablebase
tablebase_path: "data/endgame_4card_final.tb"
use_tablebase_values: true
use_tablebase_play: true

# Misc
seed: 42
device: "cuda"
experiment_name: "alphazero_v2_10sim"
checkpoint_dir: "checkpoints/alphazero_v2_10sim"

# Full opponent suite
eval_opponents:
  - random
  - heuristic
  - aggressive
  - defensive
  - queue
  - skunk
  - noisy
  - online
  - outcome_heuristic
  - distilled_outcome
  - mcts-100
  - mcts-500
  - "neural:checkpoints/v4/iter_949.pt"
  - "neural:checkpoints/92max.pt"

"""Training and tournament infrastructure for Beasty Bar."""

from __future__ import annotations

from .curriculum import (
    CURRICULUM_LEVELS,
    MIN_SPECIES_FOR_GAME,
    OPPONENT_STAGES,
    CheckpointInfo,
    CurriculumConfig,
    CurriculumScheduler,
    CurriculumState,
    HistoricalPool,
    OpponentMix,
    create_curriculum_game,
    get_curriculum_level_for_species_count,
    get_opponent_type_name,
    load_curriculum_state,
    load_historical_pool,
    sample_opponent,
    save_curriculum_state,
    save_historical_pool,
    validate_species_whitelist,
)
from .elo import EloRating, Leaderboard
from .evaluation import (
    EvaluationConfig,
    EvaluationResult,
    compare_agents,
    create_evaluation_report,
    create_opponent,
    estimate_elo,
    evaluate_agent,
    is_significantly_better,
    log_evaluation_results,
    wilson_confidence_interval,
)
from .model_selection import (
    EarlyStopping,
    ModelRecord,
    ModelSelectionConfig,
    ModelTracker,
    cleanup_old_checkpoints,
    compare_checkpoints,
    create_model_selection,
    extract_score,
)
from .opponent_pool import (
    CheckpointEntry,
    OpponentConfig,
    OpponentPool,
    OpponentType,
    SampledOpponent,
    create_opponent_network,
)
from .ppo import (
    TORCH_AVAILABLE,
    PolicyValueNetwork,
    PPOBatch,
    PPOConfig,
    RolloutData,
    compute_gae,
    entropy_bonus,
    iterate_minibatches,
    policy_loss,
    ppo_update,
    process_rollout,
    train_step,
    value_loss,
)
from .ppo_warmstart import (
    PPOWarmstartConfig,
    PPOWarmstartTrainer,
    load_warmstart_checkpoint,
)
from .progressive_schedule import (
    BaseSchedule,
    CosineSchedule,
    ExponentialSchedule,
    LinearSchedule,
    ProgressiveMCTSSchedule,
    ScheduleState,
    ScheduleType,
    StepSchedule,
    WinRateSchedule,
    linear_schedule,
    step_schedule,
    winrate_schedule,
)
from .replay_buffer import Batch, ReplayBuffer, TrajectoryBoundary, Transition
from .self_play import (
    GameTrajectory,
    SelfPlayStats,
    compute_action_distribution,
    compute_stats,
    create_game_seeds,
    generate_games,
    generate_seed_sequence,
    play_game,
    set_self_play_seed,
    trajectories_to_transitions,
    trajectory_to_player_transitions,
)
from .trajectory import (
    MCTSPendingStep,
    MCTSStep,
    PendingStep,
    PPOPendingStep,
    PPOStep,
    TrajectoryStep,
)
from .tournament import MatchResult, Tournament, TournamentConfig
from .tracking import (
    ConsoleTracker,
    ExperimentTracker,
    WandbTracker,
    create_tracker,
    log_evaluation,
    log_self_play_stats,
    log_training_step,
)
from .utils import inference_mode, training_mode
from .checkpoint_manager import CheckpointManager
from .game_generator import GameGenerator
from .trainer import (
    Trainer,
    TrainingConfig,
    create_trainer_from_checkpoint,
    get_learning_rate,
    load_training_checkpoint,
    save_training_checkpoint,
    set_learning_rate,
)
from .value_diagnostics import (
    ValueCalibrationTracker,
    check_cold_start_failure,
    diagnose_value_network,
    extract_values_from_trajectories,
    log_value_diagnostics,
)
from .exploit_patch_cycle import (
    CycleConfig,
    CycleRecord,
    ExploiterInfo,
    ExploitPatchManager,
)

__all__ = [
    # Curriculum learning
    "CURRICULUM_LEVELS",
    "MIN_SPECIES_FOR_GAME",
    "OPPONENT_STAGES",
    # PPO and training
    "TORCH_AVAILABLE",
    # Progressive MCTS schedule
    "BaseSchedule",
    "Batch",
    "CheckpointEntry",
    "CheckpointInfo",
    # New refactored classes
    "CheckpointManager",
    "GameGenerator",
    "ConsoleTracker",
    "CosineSchedule",
    "CurriculumConfig",
    "CurriculumScheduler",
    "CurriculumState",
    # Exploit-patch cycle
    "CycleConfig",
    "CycleRecord",
    "ExploiterInfo",
    "ExploitPatchManager",
    "EarlyStopping",
    "EloRating",
    "EvaluationConfig",
    "EvaluationResult",
    "ExperimentTracker",
    "ExponentialSchedule",
    "GameTrajectory",
    "HistoricalPool",
    "Leaderboard",
    "LinearSchedule",
    "MCTSPendingStep",
    "MCTSStep",
    "MatchResult",
    "ModelRecord",
    "ModelSelectionConfig",
    "ModelTracker",
    # Opponent pool
    "OpponentConfig",
    "OpponentMix",
    "OpponentPool",
    "OpponentType",
    "PPOBatch",
    "PPOConfig",
    "PPOPendingStep",
    "PPOStep",
    "PPOWarmstartConfig",
    "PPOWarmstartTrainer",
    "PendingStep",
    "PolicyValueNetwork",
    "ProgressiveMCTSSchedule",
    "ReplayBuffer",
    "RolloutData",
    "SampledOpponent",
    "ScheduleState",
    "ScheduleType",
    "SelfPlayStats",
    "StepSchedule",
    "Tournament",
    "TournamentConfig",
    "Trainer",
    "TrainingConfig",
    "TrajectoryBoundary",
    "TrajectoryStep",
    "Transition",
    # Value diagnostics
    "ValueCalibrationTracker",
    "WandbTracker",
    "WinRateSchedule",
    # Training utilities
    "inference_mode",
    "training_mode",
    "check_cold_start_failure",
    "cleanup_old_checkpoints",
    "compare_agents",
    "compare_checkpoints",
    "compute_action_distribution",
    "compute_gae",
    "compute_stats",
    "create_curriculum_game",
    "create_evaluation_report",
    "create_game_seeds",
    "create_model_selection",
    "create_opponent",
    "create_opponent_network",
    "create_tracker",
    "create_trainer_from_checkpoint",
    "diagnose_value_network",
    "entropy_bonus",
    "estimate_elo",
    "evaluate_agent",
    "extract_score",
    "extract_values_from_trajectories",
    "generate_games",
    "generate_seed_sequence",
    "get_curriculum_level_for_species_count",
    "get_learning_rate",
    "get_opponent_type_name",
    "is_significantly_better",
    "iterate_minibatches",
    "linear_schedule",
    "load_curriculum_state",
    "load_historical_pool",
    "load_training_checkpoint",
    "load_warmstart_checkpoint",
    "log_evaluation",
    "log_evaluation_results",
    "log_self_play_stats",
    "log_training_step",
    "log_value_diagnostics",
    "play_game",
    "policy_loss",
    "ppo_update",
    "process_rollout",
    "sample_opponent",
    "save_curriculum_state",
    "save_historical_pool",
    "save_training_checkpoint",
    "set_learning_rate",
    "set_self_play_seed",
    "step_schedule",
    "train_step",
    "trajectories_to_transitions",
    "trajectory_to_player_transitions",
    "validate_species_whitelist",
    "value_loss",
    "wilson_confidence_interval",
    "winrate_schedule",
]

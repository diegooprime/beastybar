"""Training and tournament infrastructure for Beasty Bar."""

from __future__ import annotations

from .curriculum import (
    CURRICULUM_LEVELS,
    MIN_SPECIES_FOR_GAME,
    OPPONENT_STAGES,
    CheckpointInfo,
    CurriculumConfig,
    CurriculumScheduler,
    CurriculumState,
    HistoricalPool,
    OpponentMix,
    create_curriculum_game,
    get_curriculum_level_for_species_count,
    get_opponent_type_name,
    load_curriculum_state,
    load_historical_pool,
    sample_opponent,
    save_curriculum_state,
    save_historical_pool,
    validate_species_whitelist,
)
from .elo import EloRating, Leaderboard
from .evaluation import (
    EvaluationConfig,
    EvaluationResult,
    compare_agents,
    create_evaluation_report,
    create_opponent,
    estimate_elo,
    evaluate_agent,
    is_significantly_better,
    log_evaluation_results,
    wilson_confidence_interval,
)
from .model_selection import (
    BestModelTracker,
    EarlyStopping,
    EarlyStoppingConfig,
    ModelRecord,
    cleanup_old_checkpoints,
    compare_checkpoints,
    create_model_selection_callback,
    integrate_model_selection,
)
from .ppo import (
    TORCH_AVAILABLE,
    PolicyValueNetwork,
    PPOBatch,
    PPOConfig,
    RolloutData,
    compute_gae,
    entropy_bonus,
    iterate_minibatches,
    policy_loss,
    ppo_update,
    process_rollout,
    train_step,
    value_loss,
)
from .replay_buffer import Batch, ReplayBuffer, TrajectoryBoundary, Transition
from .self_play import (
    GameTrajectory,
    SelfPlayStats,
    TrajectoryStep,
    compute_action_distribution,
    compute_stats,
    create_game_seeds,
    generate_games,
    generate_seed_sequence,
    play_game,
    set_self_play_seed,
    trajectories_to_transitions,
    trajectory_to_player_transitions,
)
from .tournament import MatchResult, Tournament, TournamentConfig
from .tracking import (
    CompositeTracker,
    ConsoleTracker,
    ExperimentTracker,
    TensorBoardTracker,
    WandbTracker,
    create_tracker,
    log_evaluation,
    log_self_play_stats,
    log_training_step,
)
from .trainer import (
    Trainer,
    TrainingConfig,
    create_trainer_from_checkpoint,
    get_learning_rate,
    load_training_checkpoint,
    save_training_checkpoint,
    set_learning_rate,
)

__all__ = [
    # Curriculum learning
    "CURRICULUM_LEVELS",
    "MIN_SPECIES_FOR_GAME",
    "OPPONENT_STAGES",
    # PPO and training
    "TORCH_AVAILABLE",
    "Batch",
    "BestModelTracker",
    "CheckpointInfo",
    "CompositeTracker",
    "ConsoleTracker",
    "CurriculumConfig",
    "CurriculumScheduler",
    "CurriculumState",
    "EarlyStopping",
    "EarlyStoppingConfig",
    "EloRating",
    "EvaluationConfig",
    "EvaluationResult",
    "ExperimentTracker",
    "GameTrajectory",
    "HistoricalPool",
    "Leaderboard",
    "MatchResult",
    "ModelRecord",
    "OpponentMix",
    "PPOBatch",
    "PPOConfig",
    "PolicyValueNetwork",
    "ReplayBuffer",
    "RolloutData",
    "SelfPlayStats",
    "TensorBoardTracker",
    "Tournament",
    "TournamentConfig",
    "Trainer",
    "TrainingConfig",
    "TrajectoryBoundary",
    "TrajectoryStep",
    "Transition",
    "WandbTracker",
    "cleanup_old_checkpoints",
    "compare_agents",
    "compare_checkpoints",
    "compute_action_distribution",
    "compute_gae",
    "compute_stats",
    "create_curriculum_game",
    "create_evaluation_report",
    "create_game_seeds",
    "create_model_selection_callback",
    "create_opponent",
    "create_tracker",
    "create_trainer_from_checkpoint",
    "entropy_bonus",
    "estimate_elo",
    "evaluate_agent",
    "generate_games",
    "generate_seed_sequence",
    "get_curriculum_level_for_species_count",
    "get_learning_rate",
    "get_opponent_type_name",
    "integrate_model_selection",
    "is_significantly_better",
    "iterate_minibatches",
    "load_curriculum_state",
    "load_historical_pool",
    "load_training_checkpoint",
    "log_evaluation",
    "log_evaluation_results",
    "log_self_play_stats",
    "log_training_step",
    "play_game",
    "policy_loss",
    "ppo_update",
    "process_rollout",
    "sample_opponent",
    "save_curriculum_state",
    "save_historical_pool",
    "save_training_checkpoint",
    "set_learning_rate",
    "set_self_play_seed",
    "train_step",
    "trajectories_to_transitions",
    "trajectory_to_player_transitions",
    "validate_species_whitelist",
    "value_loss",
    "wilson_confidence_interval",
]
